{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Quantum Analysis Notebook\n",
    "# \n",
    "# This notebook:\n",
    "# 1. Imports your existing `01-extractfeatures.py` so we can reuse the audio-analysis and\n",
    "#    database functions/classes (like `QuantumMusicDB`).\n",
    "# 2. Defines new quantum-computing utilities (`_compute_quantum_features_from_analysis`,\n",
    "#    `quantum_pipeline_complex`) that operate on the existing `analysis_data`.\n",
    "# 3. Provides a `run_and_store_quantum_analysis` function that:\n",
    "#    - Fetches the audio analysis record by ID from your PostgreSQL DB\n",
    "#    - Computes a quantum circuit on the data\n",
    "#    - Stores the results back into the JSON (`analysis_data`) of that record.\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 0. Notebook Setup: Auto-Reload and Imports\n",
    "\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We'll assume 01-extractfeatures.py is in the same directory or along your PYTHONPATH\n",
    "import sys\n",
    "sys.path.append('.')  # or adjust path as needed\n",
    "import importlib\n",
    "\n",
    "# Attempt to import your \"01-extractfeatures.py\" module:\n",
    "ef = importlib.import_module(\"01-extractfeatures\")\n",
    "\n",
    "# From Qiskit, import what we need for the quantum circuit\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "# You can add any other imports here if needed:\n",
    "# e.g., from qiskit.visualization import plot_histogram\n",
    "\n",
    "\n",
    "# Configure logging to show only INFO-level messages.\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='[%(levelname)s] %(asctime)s - %(message)s',\n",
    "                    datefmt='%H:%M:%S')\n",
    "\n",
    "\n",
    "# --- Helper function to encode a detected raga ---\n",
    "def encode_raga(raga):\n",
    "    \"\"\"\n",
    "    Encodes a raga string into a numerical value.\n",
    "    A simple encoding: if raga is a string, compute the sum of the Unicode code points \n",
    "    modulo 100 and normalize to [0, 1]. Replace this with a domain-specific encoding as needed.\n",
    "    \"\"\"\n",
    "    if raga is None:\n",
    "        return 0.0\n",
    "    if isinstance(raga, str):\n",
    "        return (sum(ord(c) for c in raga) % 100) / 100.0\n",
    "    try:\n",
    "        return float(raga)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def scale_features_individually(features, loIr_bounds, upper_bounds):\n",
    "    \"\"\"\n",
    "    Scales each feature individually from its own [loIr, upper] range to [0, 2*pi].\n",
    "    - features: list of raw feature values.\n",
    "    - loIr_bounds: list of loIr bounds for each feature.\n",
    "    - upper_bounds: list of upper bounds for each feature.\n",
    "    Returns a list of scaled angles.\n",
    "    \"\"\"\n",
    "    scaled = []\n",
    "    for f, l, u in zip(features, loIr_bounds, upper_bounds):\n",
    "        spread = u - l if u != l else 1\n",
    "        scaled_angle = ((f - l) / spread) * 2 * np.pi\n",
    "        scaled.append(scaled_angle)\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def nonlinear_scale_features(features):\n",
    "    \"\"\"\n",
    "    Scales a list of features into rotation angles in [0, 2π] using an arctan transformation.\n",
    "    The transformation centers the features around their median and compresses them based on\n",
    "    the median absolute deviation (MAD).\n",
    "    \n",
    "    The formula for each feature f is:\n",
    "       angle = [arctan(scaling_factor * (f - median))  π/2] * 2\n",
    "    where scaling_factor = 1 / MAD (with a fallback if MAD is zero).\n",
    "    \"\"\"\n",
    "    features = np.asarray(features, dtype=float)\n",
    "    median_val = np.median(features)\n",
    "    mad = np.median(np.abs(features - median_val))\n",
    "    if mad == 0:\n",
    "        mad = np.std(features) if np.std(features) > 0 else 1.0\n",
    "    scaling_factor = 1.0 / mad\n",
    "    \n",
    "    scaled = []\n",
    "    for f in features:\n",
    "        angle = (np.arctan(scaling_factor * (f - median_val))  (np.pi / 2)) * 2\n",
    "        scaled.append(angle)\n",
    "    return scaled\n",
    "\n",
    "\n",
    "# --- Function to compute quantum features from analysis_dict ---\n",
    "# --- Carefully crafted based on musical understanding and perceptual relevance ---\n",
    "# 1. Average Pitch Deviation (sigmoid/logistic scaling)\n",
    "def scale_pitch_dev(pitch_dev_cents):\n",
    "    d0 = 432.15  # median pitch deviation\n",
    "    k = 50       # musically relevant scaling factor (tweakable)\n",
    "    angle = 2 * np.pi / (1  np.exp(-(pitch_dev_cents - d0) / k))\n",
    "    return float(angle)\n",
    "\n",
    "# 2. Average Jitter (logistic scaling)\n",
    "def scale_jitter(jitter):\n",
    "    j0 = 0.00564  # median jitter\n",
    "    a = 300       # steepness factor, musically relevant\n",
    "    angle = 2 * np.pi / (1  np.exp(-a * (jitter - j0)))\n",
    "    return float(angle)\n",
    "\n",
    "# 3. Standard Deviation of Tempo (relative tempo stability, tanh scaling)\n",
    "def scale_tempo_std(tempo_std_bpm, tempo_mean_bpm):\n",
    "    tempo_rel = tempo_std_bpm / tempo_mean_bpm\n",
    "    r = 0.025  # 2.5% variability as a perceptual threshold\n",
    "    angle = 2 * np.pi * np.tanh(tempo_rel / r)\n",
    "    return float(angle)\n",
    "\n",
    "# 4. Average Shimmer (logistic scaling)\n",
    "def scale_shimmer(shimmer):\n",
    "    s0 = 0.1087  # median shimmer\n",
    "    b = 30       # steepness factor\n",
    "    angle = 2 * np.pi / (1  np.exp(-b * (shimmer - s0)))\n",
    "    return float(angle)\n",
    "\n",
    "# 5. Average LUFS (linear scaling)\n",
    "def scale_lufs(lufs):\n",
    "    lufs_min, lufs_max = -33, -6  # derived from your mean ± range/2\n",
    "    angle = 2 * np.pi * (lufs - lufs_min) / (lufs_max - lufs_min)\n",
    "    angle = np.clip(angle, 0, 2*np.pi)\n",
    "    return float(angle)\n",
    "\n",
    "# 6. Standard Deviation of LUFS (linear scaling)\n",
    "def scale_lufs_std(lufs_std):\n",
    "    std_max = 10  # maximum expected dynamic variability\n",
    "    angle = 2 * np.pi * lufs_std / std_max\n",
    "    angle = np.clip(angle, 0, 2*np.pi)\n",
    "    return float(angle)\n",
    "\n",
    "# 7. MFCC Standard Deviation (log scaling)\n",
    "def scale_mfcc_std(mfcc_std):\n",
    "    mfcc_max = 30  # 95th percentile approximation\n",
    "    angle = 2 * np.pi * np.log1p(mfcc_std) / np.log1p(mfcc_max)\n",
    "    angle = np.clip(angle, 0, 2*np.pi)\n",
    "    return float(angle)\n",
    "\n",
    "# 8. Zero Crossing Rate (linear capped scaling, fixed bounds)\n",
    "def scale_zcr(zcr):\n",
    "    zcr_cap = 0.2\n",
    "    angle = 2 * np.pi * min(zcr, zcr_cap) / zcr_cap\n",
    "    return float(angle)\n",
    "\n",
    "# 9. Tone-to-Noise Ratio (use HNR in dB, inverse linear scaling)\n",
    "def scale_hnr(hnr_db):\n",
    "    hnr_min, hnr_max = 0, 20  # typical HNR range (0–20 dB)\n",
    "    angle = 2 * np.pi * (hnr_max - np.clip(hnr_db, hnr_min, hnr_max)) / (hnr_max - hnr_min)\n",
    "    return float(angle)\n",
    "\n",
    "# Convenience function to scale all features at once:\n",
    "def scale_all_features(features):\n",
    "    \"\"\"\n",
    "    Takes a feature vector (matching your quantum circuit order) and returns scaled angles:\n",
    "    [avg_pitch_dev, avg_jitter, std_tempo_dev, avg_shimmer, avg_lufs, std_lufs, \n",
    "     mfcc_std, avg_zcr, avg_hnr]\n",
    "    \"\"\"\n",
    "    avg_pitch_dev, avg_jitter, std_tempo_dev, avg_shimmer, avg_lufs, std_lufs, mfcc_std, avg_zcr, avg_hnr = features\n",
    "\n",
    "    angles = [\n",
    "        scale_pitch_dev(avg_pitch_dev),                      # Rx\n",
    "        scale_jitter(avg_jitter),                            # Rx\n",
    "        scale_tempo_std(std_tempo_dev, 139.56),              # Rx, using mean tempo provided\n",
    "        scale_shimmer(avg_shimmer),                          # Ry\n",
    "        scale_lufs(avg_lufs),                                # Ry\n",
    "        scale_lufs_std(std_lufs),                            # Ry\n",
    "        scale_mfcc_std(mfcc_std),                            # Rz\n",
    "        scale_zcr(avg_zcr),                                  # Rz\n",
    "        scale_hnr(avg_hnr)                                   # Rz\n",
    "    ]\n",
    "    return angles\n",
    "\n",
    "\n",
    "def _compute_quantum_features_from_analysis(analysis_dict):\n",
    "    import numpy as np\n",
    "\n",
    "    # Extract main summary & time_matrices\n",
    "    summary = analysis_dict.get(\"summary\", {})\n",
    "    time_matrices = analysis_dict.get(\"time_matrices\", {})\n",
    "    tmatrix_small = time_matrices.get(\"time_matrix_small\", [])\n",
    "\n",
    "    # 1) Summaries for pitch dev, lufs, tone_to_noise, etc.\n",
    "    pitch_dev = summary.get(\"pitch_deviation\", {})\n",
    "    avg_pitch_dev = pitch_dev.get(\"mean\", 0.0)\n",
    "\n",
    "    dyn_lufs = summary.get(\"dynamics\", {}).get(\"lufs\", {})\n",
    "    avg_lufs = dyn_lufs.get(\"mean\", 0.0)\n",
    "    std_lufs = dyn_lufs.get(\"std\", 0.0)\n",
    "\n",
    "    hnr_dict = summary.get(\"harmony_to_noise_ratio\", {})\n",
    "    avg_hnr = hnr_dict.get(\"mean\", 0.0)\n",
    "\n",
    "    # We'll also grab the 40 MFCC std from spectral_summary (already aggregated)\n",
    "    spectral_summary = summary.get(\"spectral_summary\", {})\n",
    "    mfcc_std_list = spectral_summary.get(\"mfcc_std\", [])\n",
    "    overall_mfcc_std = float(np.mean(mfcc_std_list)) if len(mfcc_std_list) > 0 else 0.0\n",
    "\n",
    "    # 2) Single-pass iteration over `time_matrix_small` for jitter, shimmer, tempo_bpm, zcr, etc.\n",
    "    jitter_vals    = []\n",
    "    shimmer_vals   = []\n",
    "    tempo_bpm_vals = []\n",
    "    zcr_vals       = []\n",
    "\n",
    "    # We only collect numeric > 0 if that’s your convention\n",
    "    for row in tmatrix_small:\n",
    "        # Jitter\n",
    "        j = row.get(\"jitter\", 0.0)\n",
    "        if isinstance(j, (int, float)) and j > 0.0:\n",
    "            jitter_vals.append(j)\n",
    "\n",
    "        # Shimmer\n",
    "        s = row.get(\"shimmer\", 0.0)\n",
    "        if isinstance(s, (int, float)) and s > 0.0:\n",
    "            shimmer_vals.append(s)\n",
    "\n",
    "        # Tempo\n",
    "        tbpm = row.get(\"tempo_bpm\", 0.0)\n",
    "        if isinstance(tbpm, (int, float)) and tbpm > 0.0:\n",
    "            tempo_bpm_vals.append(tbpm)\n",
    "\n",
    "        # ZCR\n",
    "        z = row.get(\"zcr\", 0.0)\n",
    "        if isinstance(z, (int, float)) and z > 0.0:\n",
    "            zcr_vals.append(z)\n",
    "\n",
    "    # Now compute your aggregated stats\n",
    "    avg_jitter      = float(np.mean(jitter_vals))      if jitter_vals      else 0.0\n",
    "    avg_shimmer     = float(np.mean(shimmer_vals))     if shimmer_vals     else 0.0\n",
    "    std_tempo_dev   = float(np.std(tempo_bpm_vals))    if tempo_bpm_vals   else 0.0\n",
    "    avg_zcr         = float(np.mean(zcr_vals))         if zcr_vals         else 0.0\n",
    "\n",
    "    # 3) Build final 9-element feature vector (matching your 9 qubits).\n",
    "    # Reusing your existing order: \n",
    "    #   (0) avg_pitch_dev\n",
    "    #   (1) avg_jitter\n",
    "    #   (2) std_tempo_dev\n",
    "    #   (3) avg_shimmer\n",
    "    #   (4) avg_lufs\n",
    "    #   (5) std_lufs\n",
    "    #   (6) overall_mfcc_std\n",
    "    #   (7) avg_zcr\n",
    "    #   (8) avg_tnr\n",
    "\n",
    "    feature_vector = [\n",
    "        avg_pitch_dev,      # Qubit 0 -> Rx\n",
    "        avg_jitter,         # Qubit 1 -> Rx\n",
    "        std_tempo_dev,      # Qubit 2 -> Rx\n",
    "        avg_shimmer,        # Qubit 3 -> Ry\n",
    "        avg_lufs,           # Qubit 4 -> Ry\n",
    "        std_lufs,           # Qubit 5 -> Ry\n",
    "        overall_mfcc_std,   # Qubit 6 -> Rz\n",
    "        avg_zcr,            # Qubit 7 -> Rz\n",
    "        avg_hnr             # Qubit 8 -> Rz\n",
    "    ]\n",
    "\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def quantum_pipeline_complex(feature_vector, shots):\n",
    "    \"\"\"\n",
    "    Quantum circuit pipeline for musical feature analysis.\n",
    "    Input: feature_vector - PRE-SCALED angles in the correct order:\n",
    "      [average_pitch_deviation, average_jitter, std_tempo_deviation,\n",
    "       average_shimmer, average_lufs_energy, std_lufs_energy,\n",
    "       std_mfcc, zero_crossing_rate, average_tone_to_noise_ratio]\n",
    "\n",
    "    Returns: scaled_features, counts\n",
    "    \"\"\"\n",
    "\n",
    "    from qiskit import QuantumCircuit, transpile\n",
    "    from qiskit_aer import AerSimulator\n",
    "    from qiskit.visualization import plot_histogram\n",
    "\n",
    "\n",
    "    scaled_angles = scale_all_features(feature_vector)\n",
    "    num_qubits = len(scaled_angles)\n",
    "    qc = QuantumCircuit(num_qubits, num_qubits)\n",
    "\n",
    "    # Step 1: Hadamard layer for initial superposition\n",
    "    qc.h(range(num_qubits))\n",
    "\n",
    "    # Step 2: Feature-based rotations\n",
    "    # Rx (Pitch/Tempo): qubits 0,1,2\n",
    "    qc.rx(scaled_angles[0], 0)  # avg pitch deviation\n",
    "    qc.rx(scaled_angles[1], 1)  # avg jitter\n",
    "    qc.rx(scaled_angles[2], 2)  # std tempo deviation\n",
    "\n",
    "    # Ry (Dynamics/Energy): qubits 3,4,5\n",
    "    qc.ry(scaled_angles[3], 3)  # avg shimmer\n",
    "    qc.ry(scaled_angles[4], 4)  # avg LUFS energy\n",
    "    qc.ry(scaled_angles[5], 5)  # std LUFS energy (dynamic motion)\n",
    "\n",
    "    # Rz (Timbre/ZCR/Tonal Clarity): qubits 6,7,8\n",
    "    qc.rz(scaled_angles[6], 6)  # std MFCC (timbre consistency)\n",
    "    qc.rz(scaled_angles[7], 7)  # zero-crossing rate\n",
    "    qc.rz(scaled_angles[8], 8)  # avg tone-to-noise ratio\n",
    "\n",
    "    # Step 3: Intra-group entanglement\n",
    "    # Rx group (pitch/tempo stability)\n",
    "    qc.cx(0, 1)\n",
    "    qc.cx(1, 2)\n",
    "\n",
    "    # Ry group (energy/dynamics)\n",
    "    qc.cx(3, 4)\n",
    "    qc.cx(4, 5)\n",
    "\n",
    "    # Rz group (timbre/clarity)\n",
    "    qc.cx(6, 7)\n",
    "    qc.cx(7, 8)\n",
    "\n",
    "    # Step 4: Cross-group entanglement (Inter-group Coupling)\n",
    "    qc.cx(2, 3)  # tempo stability ↔ shimmer (expressivity)\n",
    "    qc.cx(1, 4)  # jitter ↔ avg LUFS energy\n",
    "    qc.cx(0, 6)  # pitch stability ↔ timbre consistency (stylistic nuance)\n",
    "    qc.cx(5, 7)  # dynamic motion ↔ zero-crossing (rhythmic clarity)\n",
    "\n",
    "    # Step 5: Measurement\n",
    "    qc.measure(range(num_qubits), range(num_qubits))\n",
    "\n",
    "    # Optional (recommended): circuit visualization for debugging\n",
    "    circuit_diagram = qc.draw(output='text')\n",
    "    print(circuit_diagram)\n",
    "\n",
    "    # Step 6: Execute on Aer simulator\n",
    "    simulator = AerSimulator()\n",
    "    compiled_qc = transpile(qc, simulator)\n",
    "    result = simulator.run(compiled_qc, shots=shots).result()\n",
    "    counts = result.get_counts()\n",
    "\n",
    "    # Your existing function returns scaled features AND counts:\n",
    "    return scaled_angles, counts, str(circuit_diagram)\n",
    "\n",
    "\n",
    "def plot_quantum_counts(counts):\n",
    "    \"\"\"\n",
    "    Plots the measurement distribution.\n",
    "    \"\"\"\n",
    "    outcomes = list(counts.keys())\n",
    "    frequencies = list(counts.values())\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.bar(outcomes, frequencies, color='skyblue')\n",
    "    ax.set_xlabel(\"Measurement Outcome\")\n",
    "    ax.set_ylabel(\"Counts\")\n",
    "    ax.set_title(\"Quantum Measurement Distribution\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 1. Retrieves a record by ID (via your `QuantumMusicDB` instance).\n",
    "# 2. Extracts (or re-extracts) the quantum feature vector from the `analysis_data`.\n",
    "# 3. Runs the quantum circuit (`quantum_pipeline_complex`).\n",
    "# 4. Stores the new quantum results in `analysis_data[\"quantum_analysis\"]`.\n",
    "# 5. Updates the same record in the DB with the new JSON.\n",
    "\n",
    "def run_and_store_quantum_analysis(db, record_id, shots=1024):\n",
    "    \"\"\"\n",
    "    Fetches a single record from audio_analysis (by record_id),\n",
    "    recomputes quantum features & circuit results,\n",
    "    and updates the record's analysis_data with the new quantum_analysis.\n",
    "\n",
    "    :param db: QuantumMusicDB instance (from 01-extractfeatures)\n",
    "    :param record_id: primary key in the audio_analysis table\n",
    "    :param shots: number of shots for the Qiskit simulator\n",
    "    :return: Updated analysis_data or None if not found\n",
    "    \"\"\"\n",
    "    row = db.fetch_analysis(record_id)\n",
    "    if not row:\n",
    "        logging.error(f\"Record ID {record_id} not found in DB.\")\n",
    "        return None\n",
    "\n",
    "    # row format: (id, file_name, sample_rate, analysis_data)\n",
    "    analysis_data = row[3]  # analysis_data is JSONB\n",
    "\n",
    "    if \"quantum_analysis\" in analysis_data:\n",
    "        #logging.info(f\"Clearing existing quantum_analysis from record {record_id}\")\n",
    "        del analysis_data[\"quantum_analysis\"]\n",
    "\n",
    "\n",
    "    # 1) Build the feature vector from the existing analysis_data\n",
    "    feature_vector = _compute_quantum_features_from_analysis(analysis_data)\n",
    "\n",
    "    # 2) Run the quantum pipeline\n",
    "    scaled_features, measurement_counts, circuit_diagram = quantum_pipeline_complex(feature_vector, shots=shots)\n",
    "    plot_quantum_counts(measurement_counts)\n",
    "\n",
    "    # 3) Store results in analysis_data\n",
    "    # Overwrite or create a top-level \"quantum_analysis\" key\n",
    "    analysis_data[\"quantum_analysis\"] = {\n",
    "        \"feature_vector\": feature_vector,\n",
    "        \"scaled_angles\": scaled_features,\n",
    "        \"measurement_counts\": dict(measurement_counts),\n",
    "        \"circuit_diagram\": circuit_diagram\n",
    "    }\n",
    "\n",
    "    # 4) Update DB with the new analysis_data\n",
    "    from psycopg2.extras import Json\n",
    "    with db.conn.cursor() as cur:\n",
    "        update_query = \"\"\"UPDATE audio_analysis SET analysis_data = %s WHERE id = %s\"\"\"\n",
    "        cur.execute(update_query, (Json(analysis_data), record_id))\n",
    "        db.conn.commit()\n",
    "\n",
    "    logging.info(f\"Quantum analysis updated for record ID {record_id}\")\n",
    "    return analysis_data\n",
    "\n",
    "# \n",
    "# Below is an example of how to use these functions. \n",
    "# Adjust your database credentials as needed, then call `run_and_store_quantum_analysis` on a record ID.\n",
    "\n",
    "# %%\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # 1) Create or reuse a QuantumMusicDB instance (assuming same credentials as in your 01-extractfeatures.py)\n",
    "    db = ef.QuantumMusicDB(\n",
    "        db_name=ef.DB_NAME,\n",
    "        host=ef.DB_HOST,\n",
    "        user=ef.DB_USER,\n",
    "        password=ef.DB_PASSWORD\n",
    "    )\n",
    "\n",
    "    # # 2) Choose a record ID to run quantum analysis on\n",
    "    # TEST_RECORD_ID = 1908  # adjust as needed to an existing row in audio_analysis\n",
    "\n",
    "    # # 3) Run the analysis\n",
    "    # updated_data = run_and_store_quantum_analysis(db, TEST_RECORD_ID, shots=8192)\n",
    "    # if updated_data:\n",
    "    #     logging.info(\"Quantum analysis completed and stored:\")\n",
    "    #     logging.info(updated_data[\"quantum_analysis\"])\n",
    "\n",
    "    # Example: process multiple record IDs in a single pass\n",
    "    # Option A: Hardcode a list\n",
    "    #record_ids = [1908, 1909, 1910]\n",
    "\n",
    "    # Option B: Fetch from DB (example):\n",
    "    with db.conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT id FROM audio_analysis WHERE id < 2000\")\n",
    "        rows = cur.fetchall()\n",
    "    record_ids = [r[0] for r in rows]\n",
    "\n",
    "    for rec_id in record_ids:\n",
    "        updated_data = run_and_store_quantum_analysis(db, rec_id, shots=8192)\n",
    "        if updated_data:\n",
    "            logging.info(f\"Quantum analysis completed for record ID {rec_id}\")\n",
    "            #logging.info(updated_data[\"quantum_analysis\"])\n",
    "\n",
    "    # 4) (Optional) Close DB connection\n",
    "    db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantumvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
